{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na base de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Carregando o dataset\n",
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "# Convertendo a coluna 'data_ref' para datetime\n",
    "df['data_ref'] = pd.to_datetime(df['data_ref'])\n",
    "\n",
    "# Análise exploratória inicial\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando valores nulos em 'tempo_emprego' (substituindo por mediana)\n",
    "median_tempo_emprego = df['tempo_emprego'].median()\n",
    "df['tempo_emprego'] = df['tempo_emprego'].fillna(median_tempo_emprego)\n",
    "\n",
    "# Conferindo valores nulos\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando outliers em 'idade' e 'renda' (usando boxplot)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=df['idade'])\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=df['renda'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando o IQR para a coluna 'renda'\n",
    "Q1 = df['renda'].quantile(0.25)\n",
    "Q3 = df['renda'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Definindo os limites\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Removendo os outliers da coluna 'idade'\n",
    "df = df[(df['renda'] >= lower_bound) & (df['renda'] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=df['renda'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando valores únicos em variáveis categóricas\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    print(col, df[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificando variáveis categóricas (exemplo: one-hot encoding)\n",
    "df = pd.get_dummies(df, columns=['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia'])\n",
    "\n",
    "# Criando novas features (exemplo: faixa etária)\n",
    "df['faixa_etaria'] = pd.cut(df['idade'], bins=[18, 30, 45, 60, 100], labels=['18-30', '31-45', '46-60', '60+'])\n",
    "\n",
    "# Salvando o dataframe limpo\n",
    "df.to_csv('previsao_de_renda_limpo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 1 - Separe a base em treinamento e teste (25% para teste, 75% para treinamento) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregando o dataset limpo\n",
    "df = pd.read_csv('previsao_de_renda_limpo.csv')\n",
    "\n",
    "# Separando as features (X) e a variável target (y)\n",
    "X = df.drop('renda', axis=1)\n",
    "y = df['renda']\n",
    "\n",
    "# Dividindo os dados em treinamento e teste (75% treino, 25% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'data_ref', 'id_cliente', 'posse_de_veiculo',\n",
      "       'posse_de_imovel', 'qtd_filhos', 'idade', 'tempo_emprego',\n",
      "       'qt_pessoas_residencia', 'sexo_F', 'sexo_M', 'tipo_renda_Assalariado',\n",
      "       'tipo_renda_Bolsista', 'tipo_renda_Empresário',\n",
      "       'tipo_renda_Pensionista', 'tipo_renda_Servidor público',\n",
      "       'educacao_Primário', 'educacao_Pós graduação', 'educacao_Secundário',\n",
      "       'educacao_Superior completo', 'educacao_Superior incompleto',\n",
      "       'estado_civil_Casado', 'estado_civil_Separado', 'estado_civil_Solteiro',\n",
      "       'estado_civil_União', 'estado_civil_Viúvo', 'tipo_residencia_Aluguel',\n",
      "       'tipo_residencia_Casa', 'tipo_residencia_Com os pais',\n",
      "       'tipo_residencia_Comunitário', 'tipo_residencia_Estúdio',\n",
      "       'tipo_residencia_Governamental', 'faixa_etaria'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 2 - Rode uma regularização ridge com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o na base de testes. Qual o melhor modelo? ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0, R²: 0.23727809339425499\n",
      "Alpha: 0.001, R²: 0.23728806758854104\n",
      "Alpha: 0.005, R²: 0.23728820394600125\n",
      "Alpha: 0.01, R²: 0.2372883742671016\n",
      "Alpha: 0.05, R²: 0.2372897318327194\n",
      "Alpha: 0.1, R²: 0.2372914164052492\n",
      "O melhor valor de alpha é 0.1 com R² de 0.2372914164052492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Carregando o dataset limpo\n",
    "data = pd.read_csv('previsao_de_renda_limpo.csv')\n",
    "\n",
    "# Removendo a coluna irrelevante\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Convertendo a coluna 'data_ref' para datetime e extraindo features\n",
    "data['data_ref'] = pd.to_datetime(data['data_ref'])\n",
    "data['ano'] = data['data_ref'].dt.year\n",
    "data['mes'] = data['data_ref'].dt.month\n",
    "data['dia'] = data['data_ref'].dt.day\n",
    "data.drop('data_ref', axis=1, inplace=True)\n",
    "\n",
    "# Separando as features (X) e a variável target (y)\n",
    "# (Substitua 'target' pelo nome da sua variável alvo)\n",
    "X = data.drop('renda', axis=1)\n",
    "y = data['renda']\n",
    "\n",
    "# Identificando as colunas categóricas\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Criando um codificador OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Ajustando o codificador aos dados de treino\n",
    "encoder.fit(X[categorical_cols])\n",
    "\n",
    "# Transformando os dados de treino e teste\n",
    "X_encoded = pd.DataFrame(encoder.transform(X[categorical_cols]), columns=encoder.get_feature_names_out())\n",
    "X = pd.concat([X.drop(categorical_cols, axis=1), X_encoded], axis=1)\n",
    "\n",
    "# Dividindo os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Lista de valores de alpha\n",
    "alpha_values = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "resultados = {}\n",
    "\n",
    "# Loop para testar diferentes valores de alpha\n",
    "for alpha in alpha_values:\n",
    "    # Criando o modelo\n",
    "    model = Ridge(alpha=alpha)\n",
    "    \n",
    "    # Treinando o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazendo previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculando o R²\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    resultados[alpha] = r2\n",
    "\n",
    "# Imprimindo os resultados\n",
    "for alpha, r2 in resultados.items():\n",
    "    print(f\"Alpha: {alpha}, R²: {r2}\")\n",
    "\n",
    "# Encontrando o melhor modelo (o que tem o maior R²)\n",
    "melhor_alpha = max(resultados, key=resultados.get)\n",
    "print(f\"O melhor valor de alpha é {melhor_alpha} com R² de {resultados[melhor_alpha]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 3 - Faça o mesmo que no passo 2, com uma regressão LASSO. Qual método chega a um melhor resultado? ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0, R²: 0.23728803348519056\n",
      "Alpha: 0.001, R²: 0.23728945401032675\n",
      "Alpha: 0.005, R²: 0.23729327914155296\n",
      "Alpha: 0.01, R²: 0.23729849953703097\n",
      "Alpha: 0.05, R²: 0.2373393544280642\n",
      "Alpha: 0.1, R²: 0.23738815013223413\n",
      "O melhor valor de alpha é 0.1 com R² de 0.23738815013223413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "resultados = {}\n",
    "# Loop para testar diferentes valores de alpha\n",
    "for alpha in alpha_values:\n",
    "    if alpha == 0:\n",
    "        model = LinearRegression()\n",
    "    else:\n",
    "        model = Lasso(alpha=alpha, max_iter=10000)  # Aumentando o número máximo de iterações\n",
    "    \n",
    "    # Treinando o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Fazendo previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculando o R²\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    resultados[alpha] = r2\n",
    "\n",
    "# Imprimindo os resultados\n",
    "for alpha, r2 in resultados.items():\n",
    "    print(f\"Alpha: {alpha}, R²: {r2}\")\n",
    "\n",
    "# Encontrando o melhor modelo (o que tem o maior R²)\n",
    "melhor_alpha = max(resultados, key=resultados.get)\n",
    "print(f\"O melhor valor de alpha é {melhor_alpha} com R² de {resultados[melhor_alpha]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando somente o R² dos métodos(Ridge e Lasso) o maior resultado é o alpha de Lasso: 0.23738815013223413"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 4 - Rode um modelo stepwise. Avalie o na base de testes. Qual o melhor resultado? ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² na base de testes: 0.24502957887321497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar os dados\n",
    "data = pd.read_csv(\"previsao_de_renda_limpo.csv\")\n",
    "\n",
    "# Converter a coluna 'data_ref' para datetime\n",
    "data['data_ref'] = pd.to_datetime(data['data_ref'])\n",
    "\n",
    "# Criar features numéricas a partir da data \n",
    "data['ano'] = data['data_ref'].dt.year\n",
    "data['mes'] = data['data_ref'].dt.month\n",
    "data['dia_semana'] = data['data_ref'].dt.dayofweek\n",
    "\n",
    "# Remover a coluna original de data \n",
    "data.drop('data_ref', axis=1, inplace=True)\n",
    "\n",
    "# Tratar a coluna 'faixa_etaria' (exemplo usando one-hot encoding)\n",
    "data = pd.get_dummies(data, columns=['faixa_etaria'])\n",
    "\n",
    "\n",
    "# Separar as features (X) e a variável target (y)\n",
    "X = data.drop('renda', axis=1)\n",
    "y = data['renda']\n",
    "\n",
    "# Dividir os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar um modelo de regressão linear\n",
    "model = LinearRegression()\n",
    "\n",
    "# Selecionar as melhores features usando o método stepwise forward\n",
    "sfs = SequentialFeatureSelector(model, direction='forward', scoring='r2')\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "# Obter as features selecionadas\n",
    "selected_features = X_train.columns[sfs.get_support()]\n",
    "\n",
    "# Treinar o modelo final com as features selecionadas\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Fazer previsões na base de testes\n",
    "y_pred = final_model.predict(X_test[selected_features])\n",
    "\n",
    "# Calcular o R² na base de testes\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R² na base de testes:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 5 - Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos? ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge: Esse modelo é como um treinador que tenta equilibrar o time, evitando que um jogador se destaque demais e desbalanceie o jogo. Ele evita que o modelo fique \"super treinado\" (overfitting), mas às vezes não consegue identificar os jogadores mais importantes do time (features mais relevantes).\n",
    "\n",
    "Lasso: O Lasso é um treinador mais rigoroso. Ele não só equilibra o time, mas também corta os jogadores que não contribuem muito para o resultado final. Por isso, ele é bom em selecionar os jogadores-chave (features importantes).\n",
    "\n",
    "Stepwise: O Stepwise é como um técnico que vai montando o time aos poucos, testando diferentes combinações até encontrar a melhor formação. Ele é bem eficiente em encontrar a melhor equipe, mas às vezes pode escolher jogadores por acaso, sem um critério muito claro.\n",
    "\n",
    "Quem venceu o jogo?\n",
    "\n",
    "No nosso caso, o Stepwise levou a melhor. Ele conseguiu montar a melhor equipe (modelo) e obteve o melhor resultado. Isso mostra que a estratégia de selecionar as features de forma gradual foi a mais eficiente para este conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 6 - Partindo dos modelos que você ajustou, tente melhorar o R² na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis. ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro quadrático médio (MSE): 5046560.735102035\n",
      "Coeficiente de determinação (R²): 0.33919752775969436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ... (seu código existente)\n",
    "\n",
    "# Engenharia de features\n",
    "data['experiencia_profissional_por_idade'] = data['tempo_emprego'] / data['idade']\n",
    "\n",
    "# Seleção de features\n",
    "selector = SelectFromModel(RandomForestRegressor(n_estimators=100))\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Pipeline com pré-processamento e modelo\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Grid search para ajustar os hiperparâmetros\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__max_depth': [None, 5, 10]\n",
    "}\n",
    "# ... (utilizar GridSearchCV para encontrar os melhores parâmetros)\n",
    "\n",
    "# Treinar o modelo final\n",
    "pipeline.fit(X_train_selected, y_train)\n",
    "\n",
    "# Avaliar o modelo na base de testes\n",
    "y_pred = pipeline.predict(X_test_selected)\n",
    "\n",
    "# Calcular o erro quadrático médio (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Erro quadrático médio (MSE):\", mse)\n",
    "\n",
    "# Calcular o coeficiente de determinação (R²)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Coeficiente de determinação (R²):\", r2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 7 - Ajuste uma árvore de regressão e veja se consegue um melhor com ela. ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'model__ccp_alpha': 0.01, 'model__max_depth': 3, 'model__min_samples_leaf': 1, 'model__min_samples_split': 5}\n",
      "MSE da árvore de decisão: 5808550.67248494\n",
      "R² da árvore de decisão: 0.23942168815817655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Criando um pipeline com uma árvore de decisão\n",
    "tree_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', DecisionTreeRegressor())\n",
    "])\n",
    "\n",
    "# Ajustando os hiperparâmetros da árvore de decisão\n",
    "param_grid = {\n",
    "    'model__max_depth': [3, 5, 7, None],  # Incluindo None para permitir que a árvore cresça ao máximo\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4],\n",
    "    'model__ccp_alpha': [0.0, 0.01, 0.05]  # Complexidade de poda de custo\n",
    "}\n",
    "\n",
    "# Realizando a busca em grade\n",
    "grid_search = GridSearchCV(tree_pipeline, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Obtendo o melhor modelo e seus parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Seleção de features (Exemplo usando SelectFromModel)\n",
    "selector = SelectFromModel(RandomForestRegressor(n_estimators=100))\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test) \n",
    "\n",
    "\n",
    "# Balanceamento de classes (Exemplo usando SMOTE)\n",
    "if np.unique(y_train).size == 2:  # Verificar se é um problema de classificação binária\n",
    "    smote = SMOTE()\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train_selected, y_train)\n",
    "    # Utilizar X_train_res e y_train_res para treinar o modelo\n",
    "\n",
    "# Fazendo previsões com o melhor modelo\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "\n",
    "# Calculando as métricas para a árvore de decisão\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Melhores parâmetros:\", best_params)\n",
    "print(\"MSE da árvore de decisão:\", mse)\n",
    "print(\"R² da árvore de decisão:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
